{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-Swan Hunter Trading Bot Demo\n",
    "\n",
    "This notebook demonstrates the complete Black Swan Hunter system:\n",
    "1. Feature generation for dual models\n",
    "2. MFE labeling and tail event classification\n",
    "3. Model training (XGB + LSTM)\n",
    "4. Backtesting with comprehensive metrics\n",
    "5. Performance analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "ROOT = Path().resolve().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "# Import Black Swan components\n",
    "from src.data.database import TradingDatabase\n",
    "from src.features.black_swan_pipeline import BlackSwanFeaturePipeline\n",
    "from src.features.black_swan_labeling import BlackSwanLabeling\n",
    "from src.models.xgb_mfe_model import XGBMFERegressor\n",
    "from src.models.lstm_tail_model import LSTMTailClassifier\n",
    "from src.backtesting.black_swan_backtest import BlackSwanBacktester, BacktestConfig\n",
    "\n",
    "print(\"Black Swan Hunter components loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EURUSD M5 data\n",
    "symbol = 'EURUSDm'\n",
    "db_path = ROOT / 'data' / 'trading_system.db'\n",
    "db = TradingDatabase(str(db_path))\n",
    "\n",
    "# Load recent data\n",
    "with db.get_connection() as conn:\n",
    "    query = \"\"\"\n",
    "    SELECT time, open, high, low, close, IFNULL(volume, 0) as volume\n",
    "    FROM bars \n",
    "    WHERE symbol = ?\n",
    "    ORDER BY time DESC\n",
    "    LIMIT 50000\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, params=[symbol], parse_dates=['time'])\n",
    "    df = df.sort_values('time').set_index('time')\n",
    "\n",
    "print(f\"Loaded {len(df)} bars for {symbol}\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipelines\n",
    "feature_pipeline = BlackSwanFeaturePipeline()\n",
    "labeling_pipeline = BlackSwanLabeling(forecast_horizon=100)\n",
    "\n",
    "# Generate XGB features\n",
    "print(\"Generating XGB features...\")\n",
    "xgb_features = feature_pipeline.generate_xgb_features(df, symbol)\n",
    "print(f\"XGB features shape: {xgb_features.shape}\")\n",
    "\n",
    "# Generate LSTM features\n",
    "print(\"Generating LSTM features...\")\n",
    "lstm_features = feature_pipeline.generate_lstm_features(df, symbol)\n",
    "print(f\"LSTM features shape: {lstm_features.shape}\")\n",
    "\n",
    "# Generate labels\n",
    "print(\"Generating MFE labels and tail classifications...\")\n",
    "labels_dict = labeling_pipeline.generate_labels_for_symbol(df, symbol)\n",
    "\n",
    "for label_type, labels_df in labels_dict.items():\n",
    "    print(f\"{label_type}: {labels_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Label Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze MFE distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# MFE distribution for long trades\n",
    "mfe_long = labels_dict['xgb_long']['mfe_target']\n",
    "axes[0,0].hist(mfe_long, bins=50, alpha=0.7, color='green')\n",
    "axes[0,0].set_title('MFE Distribution - Long Trades')\n",
    "axes[0,0].set_xlabel('MFE (R-multiples)')\n",
    "axes[0,0].axvline(mfe_long.mean(), color='red', linestyle='--', label=f'Mean: {mfe_long.mean():.2f}R')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# MFE distribution for short trades\n",
    "mfe_short = labels_dict['xgb_short']['mfe_target']\n",
    "axes[0,1].hist(mfe_short, bins=50, alpha=0.7, color='red')\n",
    "axes[0,1].set_title('MFE Distribution - Short Trades')\n",
    "axes[0,1].set_xlabel('MFE (R-multiples)')\n",
    "axes[0,1].axvline(mfe_short.mean(), color='green', linestyle='--', label=f'Mean: {mfe_short.mean():.2f}R')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Tail class distribution for long\n",
    "tail_long = labels_dict['lstm_long']['tail_class']\n",
    "tail_counts_long = tail_long.value_counts().sort_index()\n",
    "axes[1,0].bar(tail_counts_long.index, tail_counts_long.values, alpha=0.7, color='green')\n",
    "axes[1,0].set_title('Tail Class Distribution - Long')\n",
    "axes[1,0].set_xlabel('Tail Class')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "for i, v in enumerate(tail_counts_long.values):\n",
    "    axes[1,0].text(i, v, f'{v}\\n({v/len(tail_long)*100:.1f}%)', ha='center', va='bottom')\n",
    "\n",
    "# Tail class distribution for short\n",
    "tail_short = labels_dict['lstm_short']['tail_class']\n",
    "tail_counts_short = tail_short.value_counts().sort_index()\n",
    "axes[1,1].bar(tail_counts_short.index, tail_counts_short.values, alpha=0.7, color='red')\n",
    "axes[1,1].set_title('Tail Class Distribution - Short')\n",
    "axes[1,1].set_xlabel('Tail Class')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "for i, v in enumerate(tail_counts_short.values):\n",
    "    axes[1,1].text(i, v, f'{v}\\n({v/len(tail_short)*100:.1f}%)', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n=== MFE Statistics ===\")\n",
    "print(f\"Long trades - Mean: {mfe_long.mean():.2f}R, Std: {mfe_long.std():.2f}R, Max: {mfe_long.max():.2f}R\")\n",
    "print(f\"Short trades - Mean: {mfe_short.mean():.2f}R, Std: {mfe_short.std():.2f}R, Max: {mfe_short.max():.2f}R\")\n",
    "\n",
    "print(\"\\n=== Tail Event Statistics ===\")\n",
    "extreme_long = (tail_long >= 3).sum()\n",
    "extreme_short = (tail_short >= 3).sum()\n",
    "print(f\"Extreme tail events (Class 3): Long={extreme_long} ({extreme_long/len(tail_long)*100:.3f}%), Short={extreme_short} ({extreme_short/len(tail_short)*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models (Simplified Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# XGB training data (combine long and short)\n",
    "xgb_labels_combined = pd.concat([labels_dict['xgb_long'], labels_dict['xgb_short']]).sort_index()\n",
    "common_idx_xgb = xgb_features.index.intersection(xgb_labels_combined.index)\n",
    "X_xgb = xgb_features.loc[common_idx_xgb]\n",
    "y_xgb = xgb_labels_combined.loc[common_idx_xgb]['mfe_target']\n",
    "\n",
    "# Remove symbol column\n",
    "X_xgb_numeric = X_xgb.drop('symbol', axis=1)\n",
    "\n",
    "# Split for demo (in production, use time-based splits)\n",
    "X_xgb_train, X_xgb_test, y_xgb_train, y_xgb_test = train_test_split(\n",
    "    X_xgb_numeric, y_xgb, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"XGB training data: {X_xgb_train.shape}, Test: {X_xgb_test.shape}\")\n",
    "print(f\"XGB target stats - Train mean: {y_xgb_train.mean():.2f}R, Test mean: {y_xgb_test.mean():.2f}R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost MFE model (simplified)\n",
    "print(\"Training XGBoost MFE model...\")\n",
    "xgb_model = XGBMFERegressor()\n",
    "\n",
    "# Simple training without full CV for demo\n",
    "from sklearn.model_selection import KFold\n",
    "simple_cv = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "# Note: In production, use the full training pipeline with purged CV\n",
    "xgb_model.model = xgb_model.__class__.__bases__[0](**xgb_model.params)\n",
    "X_xgb_processed = xgb_model.prepare_features(X_xgb_train, fit_scaler=True)\n",
    "xgb_model.model.fit(X_xgb_processed, y_xgb_train.values)\n",
    "xgb_model.is_fitted = True\n",
    "\n",
    "# Evaluate\n",
    "xgb_eval = xgb_model.evaluate(X_xgb_test, y_xgb_test.values)\n",
    "print(f\"XGB Test RMSE: {xgb_eval['rmse']:.3f}, RÂ²: {xgb_eval['r2_score']:.3f}\")\n",
    "\n",
    "# Feature importance\n",
    "importance = xgb_model.get_feature_importance()\n",
    "top_features = importance['top_10_features']\n",
    "print(\"\\nTop 5 XGB features:\")\n",
    "for i, (feature, score) in enumerate(top_features[:5]):\n",
    "    print(f\"{i+1}. {feature}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simulate Predictions for Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for backtesting\n",
    "print(\"Generating predictions for backtest...\")\n",
    "\n",
    "# Use test set for predictions\n",
    "xgb_predictions = xgb_model.predict(X_xgb_test)\n",
    "\n",
    "# Create predictions DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'mfe_prediction': xgb_predictions,\n",
    "    'tail_prob_0': 0.7,  # Simplified - normally from LSTM\n",
    "    'tail_prob_1': 0.2,\n",
    "    'tail_prob_2': 0.08,\n",
    "    'tail_prob_3': 0.02\n",
    "}, index=X_xgb_test.index)\n",
    "\n",
    "print(f\"Generated {len(predictions_df)} predictions\")\n",
    "print(f\"MFE prediction stats: Mean={predictions_df['mfe_prediction'].mean():.2f}R, \"\n",
    "      f\"Std={predictions_df['mfe_prediction'].std():.2f}R, \"\n",
    "      f\"Max={predictions_df['mfe_prediction'].max():.2f}R\")\n",
    "\n",
    "# Plot prediction distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(predictions_df['mfe_prediction'], bins=50, alpha=0.7, color='blue')\n",
    "plt.axvline(5.0, color='red', linestyle='--', label='Min Entry Threshold (5R)')\n",
    "plt.axvline(predictions_df['mfe_prediction'].mean(), color='green', linestyle='--', \n",
    "           label=f'Mean: {predictions_df[\"mfe_prediction\"].mean():.2f}R')\n",
    "plt.title('XGB MFE Predictions Distribution')\n",
    "plt.xlabel('Predicted MFE (R-multiples)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure backtest\n",
    "config = BacktestConfig(\n",
    "    initial_capital=100000.0,\n",
    "    base_risk_per_trade=0.005,  # 0.5% risk per trade\n",
    "    max_concurrent_positions=3,\n",
    "    min_mfe_prediction=5.0,\n",
    "    min_tail_probability=0.3,\n",
    "    stop_loss_atr_multiple=1.0,\n",
    "    partial_take_profit_r=5.0,\n",
    "    max_hold_bars=500\n",
    ")\n",
    "\n",
    "print(\"Running backtest...\")\n",
    "backtester = BlackSwanBacktester(config)\n",
    "\n",
    "# Prepare market data for backtest\n",
    "backtest_data = df.loc[predictions_df.index]\n",
    "\n",
    "# Add required technical indicators\n",
    "from src.features.technical_indicators import TechnicalIndicators\n",
    "ti = TechnicalIndicators()\n",
    "backtest_data['atr14'] = ti.calculate_atr(backtest_data['high'], backtest_data['low'], backtest_data['close'], 14)\n",
    "backtest_data['ema20'] = ti.calculate_ema(backtest_data['close'], 20)\n",
    "backtest_data['ema50'] = ti.calculate_ema(backtest_data['close'], 50)\n",
    "backtest_data['ema200'] = ti.calculate_ema(backtest_data['close'], 200)\n",
    "\n",
    "# Run backtest\n",
    "results = backtester.run_backtest(backtest_data, predictions_df)\n",
    "\n",
    "print(\"\\n=== Backtest Results ===\")\n",
    "metrics = results['performance_metrics']\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Backtest Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "equity_df = pd.DataFrame(results['equity_curve'])\n",
    "equity_df['timestamp'] = pd.to_datetime(equity_df['timestamp'])\n",
    "equity_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Equity curve\n",
    "axes[0,0].plot(equity_df.index, equity_df['equity'])\n",
    "axes[0,0].axhline(config.initial_capital, color='red', linestyle='--', alpha=0.7, label='Initial Capital')\n",
    "axes[0,0].set_title('Equity Curve')\n",
    "axes[0,0].set_ylabel('Account Value ($)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Drawdown\n",
    "equity_values = equity_df['equity'].values\n",
    "peak = np.maximum.accumulate(equity_values)\n",
    "drawdown = (peak - equity_values) / peak * 100\n",
    "axes[0,1].fill_between(equity_df.index, 0, -drawdown, alpha=0.7, color='red')\n",
    "axes[0,1].set_title('Drawdown (%)')\n",
    "axes[0,1].set_ylabel('Drawdown (%)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Trade P&L distribution\n",
    "trades_df = pd.DataFrame(results['trades'])\n",
    "if not trades_df.empty:\n",
    "    pnl_r = trades_df['pnl_r_multiple'].dropna()\n",
    "    axes[1,0].hist(pnl_r, bins=30, alpha=0.7, color='blue')\n",
    "    axes[1,0].axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1,0].axvline(pnl_r.mean(), color='green', linestyle='--', alpha=0.7, \n",
    "                     label=f'Mean: {pnl_r.mean():.2f}R')\n",
    "    axes[1,0].set_title('Trade P&L Distribution')\n",
    "    axes[1,0].set_xlabel('P&L (R-multiples)')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Cumulative P&L\n",
    "    trades_df['entry_time'] = pd.to_datetime(trades_df['entry_time'])\n",
    "    trades_df = trades_df.sort_values('entry_time')\n",
    "    trades_df['cumulative_pnl_r'] = trades_df['pnl_r_multiple'].cumsum()\n",
    "    \n",
    "    axes[1,1].plot(trades_df['entry_time'], trades_df['cumulative_pnl_r'])\n",
    "    axes[1,1].axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1,1].set_title('Cumulative P&L (R-multiples)')\n",
    "    axes[1,1].set_ylabel('Cumulative P&L (R)')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trade analysis\n",
    "if not trades_df.empty:\n",
    "    print(\"\\n=== Trade Analysis ===\")\n",
    "    winning_trades = trades_df[trades_df['pnl_r_multiple'] > 0]\n",
    "    losing_trades = trades_df[trades_df['pnl_r_multiple'] <= 0]\n",
    "    \n",
    "    print(f\"Total trades: {len(trades_df)}\")\n",
    "    print(f\"Winning trades: {len(winning_trades)} ({len(winning_trades)/len(trades_df)*100:.1f}%)\")\n",
    "    print(f\"Losing trades: {len(losing_trades)} ({len(losing_trades)/len(trades_df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(winning_trades) > 0:\n",
    "        print(f\"Average winning trade: {winning_trades['pnl_r_multiple'].mean():.2f}R\")\n",
    "        print(f\"Largest winning trade: {winning_trades['pnl_r_multiple'].max():.2f}R\")\n",
    "    \n",
    "    if len(losing_trades) > 0:\n",
    "        print(f\"Average losing trade: {losing_trades['pnl_r_multiple'].mean():.2f}R\")\n",
    "        print(f\"Largest losing trade: {losing_trades['pnl_r_multiple'].min():.2f}R\")\n",
    "    \n",
    "    # Tail events captured\n",
    "    tail_events = trades_df[trades_df['pnl_r_multiple'] >= 5.0]\n",
    "    extreme_tail_events = trades_df[trades_df['pnl_r_multiple'] >= 20.0]\n",
    "    \n",
    "    print(f\"\\nTail events captured (â¥5R): {len(tail_events)}\")\n",
    "    print(f\"Extreme tail events captured (â¥20R): {len(extreme_tail_events)}\")\n",
    "    \n",
    "    if len(tail_events) > 0:\n",
    "        print(f\"Average tail event: {tail_events['pnl_r_multiple'].mean():.2f}R\")\n",
    "        print(f\"Largest tail event: {tail_events['pnl_r_multiple'].max():.2f}R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction accuracy\n",
    "if not trades_df.empty:\n",
    "    # Compare predicted vs realized MFE\n",
    "    trades_with_pred = trades_df.dropna(subset=['mfe_prediction', 'max_favorable_excursion'])\n",
    "    \n",
    "    if len(trades_with_pred) > 0:\n",
    "        # Convert MFE to R-multiples\n",
    "        trades_with_pred['realized_mfe_r'] = trades_with_pred['max_favorable_excursion'] / trades_with_pred['atr_at_entry']\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Predicted vs Realized MFE scatter plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(trades_with_pred['mfe_prediction'], trades_with_pred['realized_mfe_r'], alpha=0.6)\n",
    "        plt.plot([0, 50], [0, 50], 'r--', alpha=0.7, label='Perfect Prediction')\n",
    "        plt.xlabel('Predicted MFE (R)')\n",
    "        plt.ylabel('Realized MFE (R)')\n",
    "        plt.title('Predicted vs Realized MFE')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Prediction error distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        prediction_error = trades_with_pred['realized_mfe_r'] - trades_with_pred['mfe_prediction']\n",
    "        plt.hist(prediction_error, bins=20, alpha=0.7, color='orange')\n",
    "        plt.axvline(0, color='red', linestyle='--', alpha=0.7)\n",
    "        plt.axvline(prediction_error.mean(), color='green', linestyle='--', alpha=0.7,\n",
    "                   label=f'Mean Error: {prediction_error.mean():.2f}R')\n",
    "        plt.xlabel('Prediction Error (Realized - Predicted)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('MFE Prediction Error Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate prediction metrics\n",
    "        from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(trades_with_pred['realized_mfe_r'], trades_with_pred['mfe_prediction']))\n",
    "        r2 = r2_score(trades_with_pred['realized_mfe_r'], trades_with_pred['mfe_prediction'])\n",
    "        mae = mean_absolute_error(trades_with_pred['realized_mfe_r'], trades_with_pred['mfe_prediction'])\n",
    "        \n",
    "        print(\"\\n=== Prediction Performance ===\")\n",
    "        print(f\"RMSE: {rmse:.3f}R\")\n",
    "        print(f\"RÂ²: {r2:.3f}\")\n",
    "        print(f\"MAE: {mae:.3f}R\")\n",
    "        print(f\"Mean prediction error: {prediction_error.mean():.3f}R\")\n",
    "        print(f\"Std prediction error: {prediction_error.std():.3f}R\")\n",
    "        \n",
    "        # Directional accuracy\n",
    "        correct_direction = ((trades_with_pred['mfe_prediction'] >= 5.0) & \n",
    "                           (trades_with_pred['realized_mfe_r'] >= 5.0)).sum()\n",
    "        total_predictions = len(trades_with_pred)\n",
    "        directional_accuracy = correct_direction / total_predictions * 100\n",
    "        \n",
    "        print(f\"\\nDirectional accuracy (â¥5R): {directional_accuracy:.1f}% ({correct_direction}/{total_predictions})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showcased the Black Swan Hunter trading system:\n",
    "\n",
    "1. **Feature Engineering**: Generated 25+ XGB features and 10+ LSTM features with ATR normalization\n",
    "2. **Labeling**: Created MFE regression targets and tail event classifications\n",
    "3. **Model Training**: Trained XGBoost for MFE prediction (LSTM training requires more data)\n",
    "4. **Backtesting**: Comprehensive walk-forward simulation with risk management\n",
    "5. **Analysis**: Performance metrics, trade analysis, and prediction accuracy\n",
    "\n",
    "### Key Insights:\n",
    "- The system focuses on detecting extreme price movements (tail events)\n",
    "- Risk management is ATR-based for consistent R-multiple analysis\n",
    "- Position sizing adapts to prediction confidence\n",
    "- Comprehensive performance tracking enables continuous improvement\n",
    "\n",
    "### Next Steps:\n",
    "1. Train LSTM model with sufficient data and proper validation\n",
    "2. Implement full walk-forward backtesting with expanding windows\n",
    "3. Optimize hyperparameters using Optuna\n",
    "4. Deploy to live trading with MT5 integration\n",
    "5. Monitor model performance and retrain regularly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
